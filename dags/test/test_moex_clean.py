"""DAG to functional test amazon S3 """
from datetime import timedelta
from random import randint

import backoff
from airflow import DAG
from airflow.operators.python import PythonOperator

from airflow.providers.amazon.aws.hooks.s3 import S3Hook
import os
import logging
import torch
import pandas as pd
import numpy as np
import datetime
from datetime import timedelta
from transformers import AutoTokenizer, AutoModel
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from itertools import product
from sklearn.metrics import make_scorer
from sklearn.model_selection import cross_val_score
import re
from sklearn.model_selection import train_test_split
import torch
from sklearn.decomposition import PCA
from airflow.utils.dates import days_ago
from botocore.exceptions import (
    ConnectTimeoutError,
    EndpointConnectionError,
    ConnectionError,
)

from catboost import CatBoostRegressor
logger = logging.getLogger(__name__)
logger.addHandler(logging.StreamHandler())

cid = "s3_connection"

DEFAULT_ARGS = {
    "owner": "Alan",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=1),
}

dag = DAG(
    "moex_clean",
    tags=["mlops"],
    catchup=False,
    start_date=days_ago(2),
    default_args=DEFAULT_ARGS,
    schedule_interval="@once",
)


def process_moex_data():
    s3 = S3Hook(
        cid,
        transfer_config_args={
            "use_threads": False,
        },
    )
    s3.download_file(
        local_path="/tmp/", preserve_file_name=True, use_autogenerated_subdir=False, key="/moex_data/moex.csv",
        bucket_name="airflow"
    )

    with open('/tmp/moex.csv', 'r', encoding='cp1251') as fin:
        text = fin.read()
        text = text.lstrip('history').lstrip('\n')

    with open('/tmp/moex2.csv', 'w', encoding='utf-8') as out:
        out.write(text)

    moex = pd.read_csv('/tmp/moex2.csv', encoding='utf-8', sep=';')

    # 2. Преобразование колонок в нужный формат
    moex.TRADEDATE = pd.to_datetime(moex.TRADEDATE, format='%d.%m.%Y')
    moex.CAPITALIZATION = moex.CAPITALIZATION.str.replace(',', '.').astype(float) / 1e12
    moex.DIVISOR = moex.DIVISOR.str.replace(',', '.').astype(float) / 1e9
    for cat in ['OPEN', 'CLOSE', 'HIGH', 'LOW']:
        moex[cat] = moex[cat].str.replace(',', '.').astype(float)

    # 4. Дропаем лишнее и убираем NaNы
    drop_columns = ['NAME', 'SHORTNAME', 'SECID', 'BOARDID', 'DURATION', 'YIELD', 'DECIMALS', 'CURRENCYID', 'VOLUME',
                    'TRADINGSESSION', 'VALUE']
    moex.drop(drop_columns, axis=1, inplace=True)
    moex = moex[moex.CAPITALIZATION.notna()]
    moex = moex[moex.DIVISOR.notna()]

    # 5. Новые признаки
    moex['RANGE_PAST'] = (moex.HIGH - moex.LOW).shift()
    moex['CLOSE_PAST'] = moex.CLOSE.shift()
    moex['DAY'] = moex.TRADEDATE.dt.day
    moex['DAY_OF_WEEK'] = moex.TRADEDATE.dt.dayofweek
    moex['MONTH'] = moex.TRADEDATE.dt.month
    moex['CAPITALIZATION_PAST'] = moex.CAPITALIZATION.shift()
    moex['DIVISOR_PAST'] = moex.DIVISOR.shift()

    moex = moex[1:]
    moex.reset_index(drop=True, inplace=True)

    moex.to_csv('/tmp/moex_clean.csv', index=False)
    os.remove("/tmp/moex.csv")
    os.remove("/tmp/moex2.csv")
    # print(moex.head(10))
    s3.load_file(
        filename="/tmp/moex_clean.csv", key=f"/moex_data/moex_clean.csv", bucket_name="airflow"
    )



gen_emmbeding = PythonOperator(
    task_id="clean",
    provide_context=True,
    python_callable=process_moex_data,
    dag=dag,
)

